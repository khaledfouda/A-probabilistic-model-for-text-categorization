{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7485be28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8762ee86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.display.max_colwidth = 5000\n",
    "import matplotlib\n",
    "import nltk\n",
    "#from nltk import sent_tokenize, word_tokenize, corpus\n",
    "#from nltk import WordNetLemmatizer\n",
    "import random\n",
    "import swifter\n",
    "import collections\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba42ccc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of prototypical words to keep.\n",
    "k = 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a60cfb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>domain</th>\n",
       "      <th>locked</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>tclass</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LazySundayBreakfast</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>19</td>\n",
       "      <td>330</td>\n",
       "      <td>self.Liberal</td>\n",
       "      <td>False</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>political</td>\n",
       "      <td>crime   democrat slogan    presidential election  anything</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                author created_utc  num_comments  score        domain  locked  \\\n",
       "0  LazySundayBreakfast  2019-01-01            19    330  self.Liberal   False   \n",
       "\n",
       "  subreddit     tclass  \\\n",
       "0   Liberal  political   \n",
       "\n",
       "                                                                   text  \n",
       "0      crime   democrat slogan    presidential election  anything        "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data file (2019&2020)\n",
    "data = pd.read_feather('../data/feather_files/data2019clean.feather')\n",
    "data = pd.concat((data,\\\n",
    "        pd.read_feather('../data/feather_files/data2020clean.feather')))\n",
    "# Take test data out\n",
    "test = data.query(\"tclass == 'test'\").reset_index(drop=True)\n",
    "data = data.query(\"tclass == 'political' or tclass=='nonpolitical'\").reset_index(drop=True)\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcb335da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if 0:\n",
    "    proto = pd.read_feather('../data/feather_files/proto.feather')\n",
    "    worddict = pd.read_feather('../data/feather_files/worddict.feather')\n",
    "    wp_in_u = pd.read_feather('../data/feather_files/wp_in_u.feather')\n",
    "    #proto2 = pd.read_feather('../data/feather_files/proto2.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2490505",
   "metadata": {},
   "source": [
    "# Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90e7fed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get text columns for training datasets\n",
    "pol = data.query(\"tclass == 'political'\").text\n",
    "nonpol = data.query(\"tclass == 'nonpolitical'\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "700484b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a long strong of all text for each of the categories to analyse\n",
    "long_str_p = ' '.join(pol)\n",
    "long_str_np = ' '.join(nonpol)\n",
    "long_str_t = ' '.join(test.text)\n",
    "# Transform that string into a list of strings\n",
    "tokens_p = long_str_p.split()\n",
    "tokens_np = long_str_np.split()\n",
    "tokens_t = long_str_t.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b3bc51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea79dfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing a WordCloud for each of them. [saving to file]\n",
    "wordcloud = WordCloud(background_color=\"white\", max_words=5000,\\\n",
    "                  contour_width=6, contour_color='steelblue', scale=3)\n",
    "# Generate the first\n",
    "print(\"Political wordcloud\")\n",
    "wordcloud.generate(long_str_p)\n",
    "wordcloud.to_image()\n",
    "wordcloud.to_file(f'../data/political_{k}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df25bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the second wordcloud [saving to file]\n",
    "print(\"non- Political wordcloud\")\n",
    "wordcloud.generate(long_str_np)\n",
    "wordcloud.to_image()\n",
    "wordcloud.to_file(f'../data/nonpolitical_{k}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05d3c41-993f-41b2-9177-609597cdda8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the third wordcloud [saving to file]\n",
    "print(\"R/Canada (test)\")\n",
    "wordcloud.generate(long_str_t)\n",
    "wordcloud.to_image()\n",
    "wordcloud.to_file(f'../data/CA_test_{k}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775bcfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the occurences of each of the words. Output: list (word, #occurences)\n",
    "print(f\"Number of words are {len(tokens_p)}, {len(tokens_np)}, and {len(tokens_t)}\")\n",
    "counter_p = collections.Counter(tokens_p)\n",
    "counter_np = collections.Counter(tokens_np)\n",
    "counter_t = collections.Counter(tokens_t)\n",
    "print(f\"Number of distinct words is {len(counter_p)}, {len(counter_np)}, and {len(counter_t)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab01869-b462-43bf-a1a0-d08fe35d4e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the top 15 common words in each category [latex code available]\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "table = PrettyTable()\n",
    "\n",
    "table.title = 'Most common 15 words in each category'\n",
    "table.add_column('Political', np.transpose(counter_p.most_common(15))[0])\n",
    "table.add_column('Non-Political', np.transpose(counter_np.most_common(15))[0])\n",
    "table.add_column('Canada', np.transpose(counter_t.most_common(15))[0])\n",
    "print(table)\n",
    "#table.get_latex_string()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbdafe7-b086-4f88-9b51-94fc4ad75577",
   "metadata": {},
   "source": [
    "Extracting first feature.\n",
    "The tabl worddict would contain for each word: #occurences in each of the categories and the scores\n",
    "Later, I will keep only the top 200 words in each category (only training categories are considered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890b695a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make a table of word - #occurances in class 1 - #occurances in class 2 [saving to file]\n",
    "worddict = pd.DataFrame({'word':counter_p.keys(),'pol_occ': counter_p.values()})\n",
    "worddict['nonpol_occ'] = worddict.word.swifter.apply(lambda x: counter_np.get(x,0))\n",
    "\n",
    "temp = pd.DataFrame({'word':counter_np.keys(), 'nonpol_occ': counter_np.values()})\n",
    "temp['pol_occ'] = temp.word.swifter.apply(lambda x: counter_p.get(x,0))\n",
    "#Merge\n",
    "worddict = pd.concat((worddict,temp)).drop_duplicates('word').sort_values(by='pol_occ',ascending=False)\n",
    "#log\n",
    "print(f\"Number of distinct words is {len(worddict)}\")\n",
    "# Drop words occuring less than n times\n",
    "n = 50\n",
    "worddict = worddict.query('pol_occ >= @n or nonpol_occ >= @n').reset_index(drop=True)\n",
    "print(f\"# words occured at least {n} times is {len(worddict)} wordds\")\n",
    "\n",
    "# Computer score a\n",
    "worddict['ssum'] = worddict.pol_occ + worddict.nonpol_occ\n",
    "worddict['sc_n'] = worddict.pol_occ / worddict.ssum\n",
    "worddict['sc_np'] = worddict.nonpol_occ / worddict.ssum\n",
    "# Remove non-words (ie. names)\n",
    "worddict = worddict[worddict.word.isin(nltk.corpus.words.words('en'))]\n",
    "# Keep top k words in each class - \n",
    "#k = 400\n",
    "temp = worddict.sort_values(by='sc_n', ascending=False)[0:k]\n",
    "temp['class'] = 'p'\n",
    "worddict = worddict.sort_values(by='sc_np', ascending=False)[0:k]\n",
    "worddict['class'] = 'np'\n",
    "worddict = pd.concat((temp, worddict))\n",
    "worddict = worddict.drop_duplicates('word')\\\n",
    ".sort_values(by='sc_n', ascending=False).reset_index(drop=True)\n",
    "print(f\"Number of words after keeping top {k} words is {len(worddict)}\")\n",
    "# save to disk\n",
    "worddict.to_feather(f'../data/feather_files/worddict_{k}.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14412113-f54f-437f-be28-5e3ff2081067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing a WordCloud for each of them. [saving to file]\n",
    "wordcloud = WordCloud(background_color=\"white\", max_words=5000,\\\n",
    "                  contour_width=6, contour_color='steelblue', scale=2)\n",
    "# Generate the first\n",
    "print(\"top political wordcloud\")\n",
    "l_p=' '.join(worddict[worddict['class']=='p'].word)\n",
    "wordcloud.generate(l_p)\n",
    "wordcloud.to_image()\n",
    "wordcloud.to_file(f'../data/political_top_{k}.png')\n",
    "# Generate the second\n",
    "print(\"top non-political wordcloud\")\n",
    "l_np=' '.join(worddict[worddict['class']=='np'].word)\n",
    "wordcloud.generate(l_np)\n",
    "wordcloud.to_image()\n",
    "wordcloud.to_file(f'../data/nonpolitical_top_{k}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e267f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wp_in_u includes the frequency of the selected words in each of the posts\n",
    "# the shape is list of lists. posts x words\n",
    "#.allow_dask_on_strings(enable=True)\\\n",
    "wp_in_u=data.text.swifter\\\n",
    "    .apply(lambda d:( [d.count(wp) for wp in worddict.word]))\n",
    "wp_in_u = pd.DataFrame(wp_in_u)\n",
    "wp_in_u.to_feather(f'../data/feather_files/wp_in_u_{k}.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63362055-77de-4a3e-859d-a2531c736551",
   "metadata": {},
   "source": [
    "--------------------\n",
    "#### Proto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693c7196",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Transform wp_in_u into a dataframe.\n",
    "# needs to loop on each post to transform individual lists.\n",
    "wp_proto = pd.DataFrame(columns = worddict.word, index=data.index)\n",
    "for i in np.arange(len(wp_in_u)):\n",
    "        wp_proto.iloc[i] = wp_in_u.iloc[i][0]\n",
    "# Detecting and fixing outliers.\n",
    "# all occurances of more than 30 will be set to 30.\n",
    "#outliers = pd.DataFrame(columns=['Word','Occurences>50'])\n",
    "def find_outliers(tt):\n",
    "    occ = ','.join([str(x) for x in np.sort(tt[tt>30])])\n",
    "    if occ == '':\n",
    "        return\n",
    "    #wp_proto[tt.name][tt.index] = 30 # For now untill I implement the score\n",
    "    return np.transpose([tt.name, occ])\n",
    "\n",
    "outliers = wp_proto.swifter.allow_dask_on_strings(enable=True).apply(find_outliers)\n",
    "outliers = outliers.values[~pd.isna(outliers.values)]\n",
    "outliers = np.transpose([ t.tolist() for t in outliers.tolist()])\n",
    "\n",
    "table = PrettyTable()\n",
    "table.title = 'Words occuring more than 30 times in a single post'\n",
    "table.add_column('word', outliers[0])\n",
    "table.add_column('high occurences', outliers[1])\n",
    "print(table)        \n",
    "\n",
    "wp_proto.to_feather(f'../data/feather_files/wp_proto_{k}.feather')\n",
    "\n",
    "\n",
    "# sum of all words in each post\n",
    "sum_proto = data.text.swifter.allow_dask_on_strings(enable=True).apply(lambda d: len(d.split()))\n",
    "# proto. Final feature (post x wp_word)\n",
    "proto = wp_proto.divide(sum_proto,axis=0)\n",
    "proto.to_feather(f'../data/feather_files/proto_{k}.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d5b1ec-23ff-49da-9926-9005d2234224",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Second score. For each class, a post gets a score\n",
    "protoc = pd.DataFrame()\n",
    "# The numerator\n",
    "protoc['sc_p'] = proto[worddict[worddict['class']=='p'].word].sum(axis=1)\n",
    "protoc['sc_np'] = proto[worddict[worddict['class']=='np'].word].sum(axis=1)\n",
    "# Divide by the denomerator (same as the previous score)\n",
    "protoc = protoc.divide(sum_proto,axis=0)\n",
    "# save to disk\n",
    "protoc.to_feather(f'../data/feather_files/protoc_{k}.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6784ed-226a-4207-94ae-bb0c50def941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of times each proto word is mentioned once, twice, ....\n",
    "# Helps to identify outliers\n",
    "#freqs_proto = wp_proto.apply(lambda d: d.value_counts(), axis=0).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e369e551",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f0851a-d856-4127-a2da-474ab9d1dec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbffcf5-6fec-44cc-9ccc-ab2fc26d4191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68ddd24-64d5-44e3-ad16-f224492f235a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923c79db-3922-469c-956e-2dd4395522a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7e0836",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec585529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2a4a13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# freqs_proto.bidens798][freqs_proto.loc[798]!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8599457a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fi = freqs_proto.index[freqs_proto.index>10]\n",
    "\n",
    "# for ind in fi:\n",
    "#     freqs_proto.loc[ind][freqs_proto.loc[ind]!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731aa0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freqs_proto.index[freqs_proto.index>10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363a3fb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lemma = WordNetLemmatizer()\n",
    "# word=\"mueller\"\n",
    "# word = lemma.lemmatize(word.lower(),pos='v')\n",
    "# word = lemma.lemmatize(word,pos='n')\n",
    "# lemma.lemmatize(word,pos='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac263bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e46387",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b562969",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5f852e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1310f2fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f64c230",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c745c492",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0ff4bf-cfca-4ee1-9a1d-2512d022373d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df06a1c5-3a39-4eeb-803c-0bc27f54a814",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7653dd1c-7444-435e-aa64-0ea0ec458ff0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2285f891-a0f0-469b-a5b3-066f6a168af4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce9a640-ebeb-4c8b-9229-0a636f0cdb70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f40b430-6cc3-4125-b349-3facb2b4802b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a50004a-ccd5-4742-bf1f-a30b3b623f35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c9daae-ee34-4d2f-8962-f324d4f29f7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3460262-6714-480e-8a1f-8925b7fa1f07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
