{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7485be28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8762ee86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.display.max_colwidth = 5000\n",
    "import matplotlib\n",
    "import nltk\n",
    "import modin\n",
    "import swifter\n",
    "import collections\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.model_selection import train_test_split\n",
    "import logging.handlers\n",
    "from prettytable import PrettyTable\n",
    "from datetime import date\n",
    "from tabulate import tabulate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ba42ccc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Log is already initiated.\n",
      "INFO:Bot:Log is already initiated.\n"
     ]
    }
   ],
   "source": [
    "# number of prototypical words to keep.\n",
    "k = 20\n",
    "log_to_file = False\n",
    "\n",
    "\n",
    "try:\n",
    "    log.info(\"Log is already initiated.\")\n",
    "except:\n",
    "    if log_to_file:\n",
    "        logging.basicConfig(filename=f\"../data/log/log_k={k}__{date.today().strftime('%d-%m-%Y')}__.log\",\n",
    "                            filemode='a',\n",
    "                            format='%(asctime)s,%(msecs)d %(name)s %(levelname)s %(message)s',\n",
    "                            datefmt='%H:%M:%S',\n",
    "                            level=logging.DEBUG)\n",
    "        log = logging.getLogger(\"Bot\")\n",
    "        log.addHandler(logging.StreamHandler())\n",
    "        log.info(\"###########################################################\")\n",
    "\n",
    "    else:\n",
    "        log = logging.getLogger(\"Bot\")\n",
    "        log.setLevel(logging.DEBUG)\n",
    "        log.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0a60cfb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A data sample\n",
      "INFO:Bot:A data sample\n",
      "                                                                      X  Y\n",
      "0      crime   democrat slogan    presidential election  anything        1\n",
      "INFO:Bot:                                                                      X  Y\n",
      "0      crime   democrat slogan    presidential election  anything        1\n",
      "The shape of the data is (505676, 2)\n",
      "INFO:Bot:The shape of the data is (505676, 2)\n",
      "Proportions of positive (political) and negative labels:\n",
      "INFO:Bot:Proportions of positive (political) and negative labels:\n",
      "1    0.683711\n",
      "0    0.316289\n",
      "Name: Y, dtype: float64\n",
      "INFO:Bot:1    0.683711\n",
      "0    0.316289\n",
      "Name: Y, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Read data file (2019&2020)\n",
    "data = pd.read_feather('../data/feather_files/pretraining/data2019clean.feather')\n",
    "data = pd.concat((data,\\\n",
    "        pd.read_feather('../data/feather_files/pretraining/data2020clean.feather')))\n",
    "# Take test data out\n",
    "test = data.query(\"tclass == 'test'\").reset_index(drop=True).rename(columns={'text':'X'})[['X']]\n",
    "data = data.query(\"tclass == 'political' or tclass=='nonpolitical'\").reset_index(drop=True)\n",
    "data['X'] = data.text\n",
    "data['Y'] = pd.get_dummies(data.tclass).drop('nonpolitical', axis=1).values.ravel()\n",
    "data = data[['X','Y']]\n",
    "log.info(\"A data sample\")\n",
    "log.info(data.head(1))\n",
    "log.info(f\"The shape of the data is {data.shape}\")\n",
    "log.info('Proportions of positive (political) and negative labels:')\n",
    "log.info(data.Y.value_counts() / data.shape[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0d0b6f24-df78-45f1-9723-b22fdd6bd2a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1], dtype=uint8)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(data.Y).iloc[:,0].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "77e97984-e18b-4e57-83b5-6aa735319b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Taking 20.0% test subset. The resulting train shape is (404540, 2) and test shape is (101136, 2)\n",
      "INFO:Bot:Taking 20.0% test subset. The resulting train shape is (404540, 2) and test shape is (101136, 2)\n"
     ]
    }
   ],
   "source": [
    "# split to train and test\n",
    "test_size = .2\n",
    "train, valid = train_test_split(data,test_size=test_size, random_state=100,shuffle=True, stratify=data.Y)\n",
    "#data=None\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "valid.reset_index(drop=True, inplace=True)\n",
    "log.info(f\"Taking {round(.2*100,2)}% test subset. The resulting train shape is {train.shape} and test shape is {valid.shape}\" )\n",
    "# train.to_feather(f'../data/feather_files/splits/train_{k}.feather')\n",
    "# valid.to_feather(f'../data/feather_files/splits/valid_{k}.feather')\n",
    "# test.to_feather(f'../data/feather_files/splits/test.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b3b9e5-17be-40f4-8e51-aa9af640babd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dcb335da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if 0:\n",
    "    #proto = pd.read_feather('../data/feather_files/proto_8.feather')\n",
    "    worddict = pd.read_feather('../data/feather_files/worddict_800.feather')\n",
    "    wp_proto = pd.read_feather('../data/feather_files/wp_proto_800.feather')\n",
    "    wp_in_u = pd.read_feather('../data/feather_files/wp_in_u_800.feather')\n",
    "    #proto2 = pd.read_feather('../data/feather_files/proto2.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2490505",
   "metadata": {},
   "source": [
    "# Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e7fed8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "700484b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dividng data into classes\n",
      "INFO:Bot:dividng data into classes\n",
      "Joining the series of text into one string per category\n",
      "INFO:Bot:Joining the series of text into one string per category\n",
      "Dividing those long strings into lists of words\n",
      "INFO:Bot:Dividing those long strings into lists of words\n"
     ]
    }
   ],
   "source": [
    "# get text columns for training datasets\n",
    "log.info(\"dividng data into classes\")\n",
    "pol = train.query(\"Y == 1\").X\n",
    "nonpol = train.query(\"Y == 0\").X\n",
    "pol_valid = valid.query(\"Y==1\").X\n",
    "nonpol_valid = valid.query(\"Y==0\").X\n",
    "# Get a long string of all text for each of the categories to analyse\n",
    "log.info(\"Joining the series of text into one string per category\")\n",
    "long_str_p = ' '.join(pol)\n",
    "long_str_np = ' '.join(nonpol)\n",
    "long_str_t = ' '.join(test.X)\n",
    "long_str_p_v = ' '.join(pol_valid)\n",
    "long_str_np_v = ' '.join(nonpol_valid)\n",
    "# Transform that string into a list of strings\n",
    "log.info(\"Dividing those long strings into lists of words\")\n",
    "tokens_p = long_str_p.split()\n",
    "tokens_np = long_str_np.split()\n",
    "tokens_t = long_str_t.split()\n",
    "tokens_p_v = long_str_p_v.split()\n",
    "tokens_np_v = long_str_np_v.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fe9a6e-2463-49ab-bfc0-eac6c0927e8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "66eaf8bb-70bb-49bf-83c2-8d582235854e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. P(w|y)\n",
    "# use x1=long_str_p, x0=long_str_np, \n",
    "W = pd.Series(list((set(tokens_np) | set(tokens_p))))\n",
    "PWY = pd.DataFrame(data=0, index=W, columns=[0,1])\n",
    "cw0 = collections.Counter(tokens_np)\n",
    "PWY.loc[cw0.keys(),0] =list(cw0.values())\n",
    "cw1 = collections.Counter(tokens_p)\n",
    "PWY.loc[cw1.keys(),1] =list(cw1.values())\n",
    "NUMES = PWY.copy()\n",
    "PSUM = PWY[0]+PWY[1]\n",
    "#PWY = PWY.divide(PSUM, axis=0)\n",
    "PWY[0] = PWY[0] / len(tokens_np)\n",
    "PWY[1] = PWY[1] / len(tokens_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df84126-4c98-4ab2-aecd-67a7c9eb4c12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b4b1e199-4d02-4df0-a722-b45d8e2d3cfb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.99 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "t = train.X.map(lambda d : \" \".join(set(d.split())))\n",
    "t = ' '.join(t).split()\n",
    "PW = pd.Series(collections.Counter(t))\n",
    "PW = PW.divide(len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "557b02b4-9b29-4ddc-adba-ae26fca62624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PSCoRE\n",
    "\n",
    "PScore = (2 * PWY.multiply(PW,axis=0)) / PWY.add(PW, axis=0)\n",
    "#PScore = (.5* PWY).add(.5 * PW,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "79dea9fd-6140-43bd-924b-0c96ad4a0e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "WP = pd.DataFrame()\n",
    "t1 =  PScore[0].sort_values(ascending=False)[0:1000].index\n",
    "#WP = WP.append(pd.DataFrame({'word':t, 'y0' :1, 'y1':0}), ignore_index=True)\n",
    "t2 = PScore[1].sort_values(ascending=False)[0:1000].index\n",
    "WP = pd.DataFrame({'word':list( set(t1)|set(t2)), 'y0':0, 'y1':0})\n",
    "WP.index = WP.word\n",
    "WP.loc[t1,'y0'] = 1\n",
    "WP.loc[t2,'y1'] = 1\n",
    "#WP = WP.append(pd.DataFrame({'word':t, 'y' :1}), ignore_index=True)\n",
    "#WP = set(WP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4469def-8fd6-4c18-919a-da55abbf92ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2bc1c7b3-d966-4aa1-8d5a-2051e925d23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P(Y|wp)\n",
    "NUMES = NUMES.loc[WP.index,]\n",
    "PSUM = NUMES[0]+NUMES[1]\n",
    "NUMES = NUMES.divide(PSUM, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a670359f-ec66-4402-9a67-e9f68f70db43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>chief</th>\n",
       "      <td>0.062961</td>\n",
       "      <td>0.937039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ally</th>\n",
       "      <td>0.131485</td>\n",
       "      <td>0.868515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mueller</th>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.999750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dirty</th>\n",
       "      <td>0.851216</td>\n",
       "      <td>0.148784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>difficult</th>\n",
       "      <td>0.851595</td>\n",
       "      <td>0.148405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mistake</th>\n",
       "      <td>0.797508</td>\n",
       "      <td>0.202492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hack</th>\n",
       "      <td>0.221374</td>\n",
       "      <td>0.778626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water</th>\n",
       "      <td>0.890946</td>\n",
       "      <td>0.109054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>find</th>\n",
       "      <td>0.777635</td>\n",
       "      <td>0.222365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>choice</th>\n",
       "      <td>0.617818</td>\n",
       "      <td>0.382182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1490 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0         1\n",
       "word                         \n",
       "chief      0.062961  0.937039\n",
       "ally       0.131485  0.868515\n",
       "mueller    0.000250  0.999750\n",
       "dirty      0.851216  0.148784\n",
       "difficult  0.851595  0.148405\n",
       "...             ...       ...\n",
       "mistake    0.797508  0.202492\n",
       "hack       0.221374  0.778626\n",
       "water      0.890946  0.109054\n",
       "find       0.777635  0.222365\n",
       "choice     0.617818  0.382182\n",
       "\n",
       "[1490 rows x 2 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a7471c19-892b-48e4-9a87-90c9137d3630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebafb626766f477b96723fc973e46a38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dask Apply:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ex = valid.X[0]\n",
    "x = valid.X\n",
    "#pred = x.swifter.allow_dask_on_strings().apply(lambda d: NUMES.loc[ NUMES.index.intersection(d.split()),:].sum(axis=0).argmax())\n",
    "flag = x.swifter.apply(lambda d: len(NUMES.index.intersection(d.split())) == 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87c65bc7-33ca-4172-a005-78e7b5b1d77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d543f1fd-536e-41fb-9c41-a6f7e6200aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {\n",
    "                'alpha': [.2, .4, .5, .6, .8],\n",
    "                'k': [200, 400, 600, 800, 1000, 1200, 1400]\n",
    "            }\n",
    "keys = options.keys()\n",
    "values = (options[key] for key in keys)\n",
    "combinations = [dict(zip(keys, combination)) for combination in itertools.product(*values)]\n",
    "#(combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "855a9066-0a8f-4f24-b657-a7b19de4b949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinations[1]['alpha']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ae32b347-74ed-42d1-820d-49beb438114a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9897800670427602"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = valid.X[1]\n",
    "#pred = valid.X.swifter.apply(lambda d : NUMES.loc[ [a for a in d.split() if a in NUMES.index] ,:].sum(axis=0).argmax())\n",
    "NUMES.loc[ NUMES.index.intersection(d.split()),:].values.max() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c4a1cbfe-745e-493f-82c4-ec310d3d99b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nonresponse    0.010422\n",
       "Accuracy       0.870995\n",
       "f1_score       0.898476\n",
       "Precision      0.972525\n",
       "Recall         0.834905\n",
       "Accuracy_a     0.874033\n",
       "f1_score_a     0.901562\n",
       "Precision_a    0.972525\n",
       "Recall_a       0.840251\n",
       "dtype: float64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCORER(valid.Y, pred, flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fb748eae-5218-4fa7-8336-26cfbd131b1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nonresponse    0.010422\n",
       "Accuracy       0.870995\n",
       "f1_score       0.898476\n",
       "Precision      0.972525\n",
       "Recall         0.834905\n",
       "Accuracy_a     0.874033\n",
       "f1_score_a     0.901562\n",
       "Precision_a    0.972525\n",
       "Recall_a       0.840251\n",
       "dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCORER(valid.Y, pred, flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cbb511fa-6210-48e7-8618-98e6e9ed560f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "def SCORER(y_true, y_pred, flag):\n",
    "    scr = pd.Series(dtype=np.float32)\n",
    "    scr[\"nonresponse\"] = flag.value_counts().loc[1] / len(flag)\n",
    "    scr[\"Accuracy\"] = accuracy_score(y_true, y_pred)\n",
    "    scr[\"f1_score\"] = f1_score(y_true, y_pred)\n",
    "    scr['Precision'] = precision_score(y_true, y_pred)\n",
    "    scr['Recall'] = recall_score(y_true, y_pred)\n",
    "    scr[\"Accuracy_a\"] = accuracy_score(y_true[flag == 0], y_pred[flag == 0])\n",
    "    scr[\"f1_score_a\"] = f1_score(y_true[flag == 0], y_pred[flag == 0])\n",
    "    scr['Precision_a'] = precision_score(y_true[flag == 0], y_pred[flag == 0])\n",
    "    scr['Recall_a'] = recall_score(y_true[flag == 0], y_pred[flag == 0])\n",
    "    return scr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc3d8d5-25ce-41fe-912b-baabd26a0c83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "00075097-82ac-4273-98a6-aba32b6de4b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d', 'eee', 'd']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [\"d\", \"eee\", \"dd\", \"d\"]\n",
    "b = [\"eee\", \"grgfgr\", \"d\"]\n",
    "[i for i in a if i in b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b2b6768a-86e5-48e9-81f6-507681e92081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.96 s\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81b2b1f-420b-4c3b-aecb-2fae33430a1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d2dd8b-1618-424b-a74e-c02d70b31555",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320d7f94-867e-49af-8855-01ee5d47f928",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c716c2e0-a49f-4f31-990d-863da3f6db76",
   "metadata": {},
   "outputs": [],
   "source": [
    "cw1 = W.swifter.apply(lambda d: long_str_p.count(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b3bc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENS = pd.Series(TOKENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea79dfb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wp_in_u=train.X.swifter.apply(lambda d:( [d.count(wp) for wp in worddict.word]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df25bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENS = tokens_p\n",
    "xx = tokens_p[0]\n",
    "#ouu=[pol.str.count(x) for x in TOKENS]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda6dde2-2b9d-4b71-901b-360b2cef26db",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = pol[5]\n",
    "ouu = collections.Counter(xx.split())\n",
    "ouu.keys()\n",
    "TOKENS[0:5]\n",
    "NUME[1,TOKENS[TOKENS.isin(ouu.keys())].index] = list(ouu.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc32c2c2-692e-425c-86fa-98a4a1a07df6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUME = np.zeros((len(pol),len(TOKENS)), dtype=np.int16)\n",
    "TOKENS[ouu].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90c4a81-e7fc-4407-aa32-b95017156ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(ouu.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05d3c41-993f-41b2-9177-609597cdda8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775bcfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the occurences of each of the words. Output: list (word, #occurences)\n",
    "log.info(\"Couting the occurences of each word per class\")\n",
    "log.info(f\"Total umber of words (training+validation) is:\")\n",
    "log.info(f\"Political: {len(tokens_p)+len(tokens_p_v)}, nonpolitical: {len(tokens_np)+len(tokens_np_v)}, and test: {len(tokens_t)}\")\n",
    "counter_p = collections.Counter(tokens_p)\n",
    "counter_np = collections.Counter(tokens_np)\n",
    "counter_t = collections.Counter(tokens_t)\n",
    "log.info(f\"Number of distinct training words for each class is {len(counter_p)}, {len(counter_np)}, and {len(counter_t)}\")\n",
    "\n",
    "log.info(\"Visualizing the top 15 common words in each category [latex code below]\")\n",
    "\n",
    "table = PrettyTable()\n",
    "\n",
    "table.title = 'Most common 15 words in each category '\n",
    "table.add_column('Political', np.transpose(collections.Counter(tokens_p+tokens_p_v).most_common(15))[0])\n",
    "table.add_column('Non-Political', np.transpose(collections.Counter(tokens_np+tokens_np_v).most_common(15))[0])\n",
    "table.add_column('Canada', np.transpose(counter_t.most_common(15))[0])\n",
    "log.info(table)\n",
    "log.info(table.get_latex_string())\n",
    "del tokens_p, tokens_np, tokens_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab01869-b462-43bf-a1a0-d08fe35d4e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbdafe7-b086-4f88-9b51-94fc4ad75577",
   "metadata": {},
   "source": [
    "Extracting first feature.\n",
    "The tabl worddict would contain for each word: #occurences in each of the categories and the scores\n",
    "Later, I will keep only the top 200 words in each category (only training categories are considered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890b695a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "log.info(\"Creating a table of the number of occurence of each word in each of the two classes. Saved as worddict\")\n",
    "# Make a table of word - #occurances in class 1 - #occurances in class 2 [saving to file]\n",
    "worddict = pd.DataFrame({'word':counter_p.keys(),'pol_occ': counter_p.values()})\n",
    "worddict['nonpol_occ'] = worddict.word.swifter.apply(lambda x: counter_np.get(x,0))\n",
    "#----------------------------- class 2\n",
    "temp = pd.DataFrame({'word':counter_np.keys(), 'nonpol_occ': counter_np.values()})\n",
    "temp['pol_occ'] = temp.word.swifter.apply(lambda x: counter_p.get(x,0))\n",
    "#Merge\n",
    "worddict = pd.concat((worddict,temp)).drop_duplicates('word').sort_values(by='pol_occ',ascending=False)\n",
    "#------------------------------------------------------------------\n",
    "#log\n",
    "log.info(f\"Number of distinct words is {len(worddict)}\")\n",
    "n=50\n",
    "log.info(f\"Droping word occuring less than {n} times\")\n",
    "# Drop words occuring less than n times\n",
    "worddict = worddict.query('pol_occ >= @n or nonpol_occ >= @n').reset_index(drop=True)\n",
    "log.info(f\" number of words occuring at least {n} times is {len(worddict)} words\")\n",
    "\n",
    "# Computer score a\n",
    "log.info(\"Computing proto score. Equation 1. Objective, choose top k words\")\n",
    "worddict['ssum'] = worddict.pol_occ + worddict.nonpol_occ\n",
    "worddict['sc_p'] = worddict.pol_occ / worddict.ssum\n",
    "worddict['sc_np'] = worddict.nonpol_occ / worddict.ssum\n",
    "# Remove non-words (ie. names)\n",
    "log.info(\"Removing names and other non-recognizable words. Unfortunately, some names would be detected since they hold a second meaning\")\n",
    "worddict = worddict[worddict.word.isin(nltk.corpus.words.words('en'))]\n",
    "# Keep top k words in each class - \n",
    "#k = 400\n",
    "log.info(f\"keeping top {k} words in each class\")\n",
    "temp = worddict.sort_values(by='sc_p', ascending=False)[0:k]\n",
    "temp['Y'] = 1\n",
    "worddict = worddict.sort_values(by='sc_np', ascending=False)[0:k]\n",
    "worddict['Y'] = 0\n",
    "worddict = pd.concat((temp, worddict))\n",
    "worddict = worddict.drop_duplicates('word')\\\n",
    ".sort_values(by='sc_p', ascending=False).reset_index(drop=True)\n",
    "log.info(f\"Number of words after keeping top {k} words is {len(worddict)}\")\n",
    "# save to disk\n",
    "#worddict.to_feather(f'../data/feather_files/worddict_{k}.feather')\n",
    "#del temp, counter_p, counter_np, counter_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14412113-f54f-437f-be28-5e3ff2081067",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e267f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# wp_in_u includes the frequency of the selected words in each of the posts\n",
    "# the shape is list of lists. posts x words\n",
    "#.allow_dask_on_strings(enable=True)\\\n",
    "#.swifter.allow_dask_on_strings(enable=True).apply\n",
    "log.info(\"Couting the occurence of the chosen words inside each of the posts. The resulting dataframe is of shape (number of posts)x(2k).\")\n",
    "wp_in_u=train.X.swifter.apply(lambda d:( [d.count(wp) for wp in worddict.word]))\n",
    "wp_in_u = pd.DataFrame(wp_in_u)\n",
    "#wp_in_u.to_feather(f'../data/feather_files/wp_in_u_{k}.feather')\n",
    "log.info(f\"saved as wp_in_u_{k} with the dimension of {wp_in_u.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63362055-77de-4a3e-859d-a2531c736551",
   "metadata": {},
   "source": [
    "--------------------\n",
    "#### Proto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0543a14-27e5-434b-a951-d847fc70bc90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693c7196",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#Transform wp_in_u into a dataframe.\n",
    "# needs to loop on each post to transform individual lists.\n",
    "log.info(f\"Transforming the previous variable into a dataframe. saved as wp_proto_{k}\")\n",
    "wp_proto = wp_in_u.swifter.apply(lambda d: pd.Series(d[0]), axis=1)\n",
    "wp_proto.columns = worddict.word\n",
    "wp_proto.index = train.index\n",
    "#------------------------------------------------------------------------------------------------------------\n",
    "# Detecting and fixing outliers.\n",
    "# all occurances of more than 30 will be set to 30.\n",
    "#outliers = pd.DataFrame(columns=['Word','Occurences>50'])\n",
    "log.info(\"Finding outliers and printing them.\")\n",
    "log.info(\"Words appearing more than 30 times in the same post are considered as outliers.\")\n",
    "log.info(\"No action is being taken atm but we can consider resetting them to 30\")\n",
    "# def find_outliers(tt):\n",
    "#         occ = ','.join([str(x) for x in np.sort(tt[tt>50])])\n",
    "#         if occ == '':\n",
    "#             return\n",
    "#         #wp_proto[tt.name][tt.index] = 30 # For now untill I implement the score\n",
    "#         return np.transpose([tt.name, occ])\n",
    "\n",
    "\n",
    "# try:\n",
    "    \n",
    "#     outliers = wp_proto.swifter.apply(find_outliers)\n",
    "#     outliers = outliers.values[~pd.isna(outliers.values)]\n",
    "#     outliers = np.transpose([ t.tolist() for t in outliers.tolist()])\n",
    "\n",
    "#     table = PrettyTable()\n",
    "#     table.title = 'Words occuring more than 30 times in a single post'\n",
    "#     table.add_column('word', outliers[0])\n",
    "#     table.add_column('high occurences', outliers[1])\n",
    "#     log.info(table)        \n",
    "# except:\n",
    "#     pass\n",
    "    \n",
    "wp_proto.to_feather(f'../data/feather_files/wp_proto_{k}.feather')\n",
    "\n",
    "\n",
    "# sum of all words in each post\n",
    "log.info(\"Computing the sum of words in each post\")\n",
    "sum_proto = train.X.swifter.apply(lambda d: len(d.split()))\n",
    "# proto. Final feature (post x wp_word)\n",
    "log.info(\"Creating the first set of features, equation 2. (#occurence of wp in u)/(#words in u). A table of (#posts)x(2k)\")\n",
    "proto = wp_proto.divide(sum_proto,axis=0)\n",
    "proto.to_feather(f'../data/feather_files/proto_{k}.feather')\n",
    "log.info(f\"saved as proto_{k}\")\n",
    "\n",
    "#del train, wp_proto, outliers, wp_in_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dc384d-202c-4d8b-988a-7f2e45fc37e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06f9cf1-30cc-4da8-b7ec-0b13b006b1ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d5b1ec-23ff-49da-9926-9005d2234224",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Second score. For each class, a post gets a score\n",
    "log.info(\"The next feature is a score per (post,class)\")\n",
    "proto_train = pd.DataFrame()\n",
    "# The numerator\n",
    "proto_train['sc_p'] = proto[worddict.query(\"Y == 1\").word].sum(axis=1)\n",
    "proto_train['sc_np'] = proto[worddict.query(\"Y == 0\").word].sum(axis=1)\n",
    "# Divide by the denomerator (same as the previous score)\n",
    "proto_train = proto_train.divide(sum_proto,axis=0)\n",
    "log.info('Computing training set predictions (1 if matches, 0 if not, nonres_flag = -1 if both probabilities are 0')\n",
    "proto_train['Y'] = train.Y\n",
    "proto_train['Y_pred'] = (proto_train.sc_p > proto_train.sc_np).astype(int)\n",
    "#proto_train['accuracy'] = (proto_train.Y == proto_train.Y_pred).astype(int)\n",
    "proto_train['nonresp_flag'] = 0\n",
    "proto_train.loc[proto_train.eval('sc_p == sc_np == 0'),'nonresp_flag'] = 1\n",
    "#proto_train.query('sc_p == sc_np == 0')['nonresp_flag'] = 1\n",
    "log.info('saving to disk')\n",
    "# save to disk\n",
    "proto_train.to_feather(f'../data/feather_files/proto_train_{k}.feather')\n",
    "log.info(f\"saved as proto_train_{k}\")\n",
    "log.info(proto_train.sample(3))\n",
    "#del proto_train, worddict, sum_proto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47312fbf-744c-4959-8d91-a1a9d9470dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "log.info(\"Computing the probabilities of classes given proto words\")\n",
    "log.info(\"The pclass is an assignment to the class of higher probability\")\n",
    "# probabilities of class given a proto word.\n",
    "# the pclass is an  assignment to the class of higher probability\n",
    "# Rows are words\n",
    "protom = pd.DataFrame()\n",
    "    \n",
    "protom['sc_p'] = proto.swifter.apply(lambda d: d.mul(proto_train.sc_p).sum())\n",
    "protom['sc_np'] = proto.swifter.apply(lambda d: d.mul(proto_train.sc_np).sum())\n",
    "protom['Y'] = protom.swifter.apply(lambda d: d.sc_p > d.sc_np,axis=1)\n",
    "protom['word'] = proto.columns\n",
    "log.info(\"dataframe was created successfully. Saving to disk...\")\n",
    "log.info(protom.sample(3))\n",
    "protom.reset_index(drop=True).to_feather(f'../data/feather_files/proto_W_C_{k}.feather')\n",
    "log.info('saved to disk')\n",
    "#del proto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b5ba92-7314-4bb7-b1ca-b0fdcc84f721",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "log.info(\"Computing validation set predictions\")\n",
    "proto_valid = pd.DataFrame()\n",
    "log.info(\"The class prob of a post is the sum of class|word probabilties for all proto word in class and in post\")\n",
    "\n",
    "temp = protom[['sc_p','sc_np']]\n",
    "proto_valid[['sc_p','sc_np']] = valid.X.swifter.apply(lambda d :  temp[protom.word.isin(d.split())].sum())[['sc_p','sc_np']]\n",
    "\n",
    "\n",
    "proto_valid['Y'] = valid.Y # 1 for p and 0 for np\n",
    "\n",
    "proto_valid['Y_pred'] = (proto_valid.sc_p > proto_valid.sc_np).astype(int)  # 1 for p and 0 for np\n",
    "#proto_valid['accuracy'] = (proto_valid.Y == proto_valid.Y_pred).astype(int)\n",
    "proto_valid['nonresp_flag'] = 0\n",
    "proto_valid.loc[proto_valid.eval('sc_p == sc_np == 0'),'nonresp_flag'] = 1\n",
    "log.info('saving to disk')\n",
    "# save to disk\n",
    "proto_train.to_feather(f'../data/feather_files/proto_valid_{k}.feather')\n",
    "log.info(f\"saved as proto_valid_{k}\")\n",
    "log.info(proto_valid.sample(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d404a3c8-1435-49ac-aceb-f93264c46a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "def scorer(y_true, y_pred, flag):\n",
    "    scr = pd.Series(dtype=np.float32)\n",
    "    scr[\"nonresponse\"] = flag.value_counts().loc[1] / len(flag)\n",
    "    scr[\"f1_score\"] = f1_score(y_true, y_pred)\n",
    "    scr[\"f1_score_a\"] = f1_score(y_true[flag==0], y_pred[flag==0])\n",
    "    scr[\"Accuracy\"] = accuracy_score(y_true, y_pred)\n",
    "    scr[\"Accuracy_a\"] = accuracy_score(y_true[flag==0], y_pred[flag==0])\n",
    "    return scr\n",
    "\n",
    "scores = pd.DataFrame()\n",
    "\n",
    "\n",
    "scores[f'Valid_{k}'] = scorer(proto_valid.Y, proto_valid.Y_pred, proto_valid.nonresp_flag)\n",
    "scores[f'Train_{k}'] = scorer(proto_train.Y, proto_train.Y_pred, proto_train.nonresp_flag)\n",
    "\n",
    "scores.reset_index().to_feather(f'../data/feather_files/scores_k={k}.feather')\n",
    "#-----------------------------------------------------------------------------------\n",
    "print(tabulate(scores, headers='keys', tablefmt='psql'))\n",
    "log.info(tabulate(scores, headers='keys', tablefmt='latex_raw'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6784ed-226a-4207-94ae-bb0c50def941",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f0851a-d856-4127-a2da-474ab9d1dec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbffcf5-6fec-44cc-9ccc-ab2fc26d4191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68ddd24-64d5-44e3-ad16-f224492f235a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923c79db-3922-469c-956e-2dd4395522a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7e0836",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec585529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac263bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e46387",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b562969",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5f852e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1310f2fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f64c230",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c745c492",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0ff4bf-cfca-4ee1-9a1d-2512d022373d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df06a1c5-3a39-4eeb-803c-0bc27f54a814",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7653dd1c-7444-435e-aa64-0ea0ec458ff0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2285f891-a0f0-469b-a5b3-066f6a168af4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce9a640-ebeb-4c8b-9229-0a636f0cdb70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f40b430-6cc3-4125-b349-3facb2b4802b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a50004a-ccd5-4742-bf1f-a30b3b623f35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c9daae-ee34-4d2f-8962-f324d4f29f7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3460262-6714-480e-8a1f-8925b7fa1f07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
