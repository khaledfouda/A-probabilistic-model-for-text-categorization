15:21:46: ######################################################################################
15:21:46: A data sample
15:21:46: +--------+-----------------------------------------------------------+-----+
|        | X                                                         |   Y |
|--------+-----------------------------------------------------------+-----|
| 431811 | meet  trump saboteur  charge  undermine biden   america   |   1 |
| 251142 | seattle  hire  justice    public work department          |   1 |
|  83616 | kamala harris  field question   stance  federally mandate |   1 |
+--------+-----------------------------------------------------------+-----+
15:21:46: The shape of the data is (505676, 2)
15:21:46: 1    0.683711
0    0.316289
Name: Y, dtype: float64
15:21:46: Taking 20.0% test subset.
15:21:46: The resulting train shape is (404540, 2) and test shape is (101136, 2)
15:21:46: dividing data into classes
15:21:46: Joining the series of text into one string per category
15:21:46: Dividing those long strings into lists of words
15:21:47: Counting the occurrences of each word per class
15:21:47: Total umber of words (training+validation) is:
15:21:47: Class 1: 2527675, Class 0: 3903092
15:21:47: Number of distinct training words for each class is
15:21:47: 25052 and 48967
15:21:47: Visualizing the top 15 common words in each category [latex code below]
15:21:48: +--------------------------------------+
| Most common 15 words in each category  |
+----------------------+---------------+
|       class 1        |    class 0    |
+----------------------+---------------+
|        trump         |      like     |
|        biden         |      make     |
|        house         |      know     |
|     coronavirus      |     think     |
|         call         |      tell     |
|       democrat       |     would     |
|      president       |      want     |
|        white         |      take     |
|       election       |      time     |
|         vote         |     people    |
|      republican      |      feel     |
|        sander        |     start     |
|        state         |      year     |
|        donald        |      come     |
|       campaign       |      look     |
+----------------------+---------------+
15:21:48: \begin{tabular}{cc}
class 1 & class 0 \\
trump & like \\
biden & make \\
house & know \\
coronavirus & think \\
call & tell \\
democrat & would \\
president & want \\
white & take \\
election & time \\
vote & people \\
republican & feel \\
sander & start \\
state & year \\
donald & come \\
campaign & look \\
\end{tabular}
15:21:48: Starting CV fit step
15:21:48: Hyperparameters: k=200, alpha=0.5, harmonic pscore=True
15:21:48: *_* Inside GetWP()
15:21:51: WP created. Number of WP words are 332
15:21:51: P(y|wp) is calculated and saved to disk as REDDIT_CV_pywp_200.feather
15:21:51: Using fontManager instance from C:\Users\Khaled\.matplotlib\fontlist-v330.json
15:21:51: Loaded backend qtagg version unknown.
15:21:51: Loaded backend QtAgg version unknown.
15:21:51: Word Cloud
15:21:51: Top of class 1
15:21:52: Word Cloud
15:21:52: Top of class 0
15:26:00: +-------------+-----------+
|             |     valid |
|-------------+-----------|
| nonresponse | 0.0652883 |
| Accuracy    | 0.813598  |
| f1_score    | 0.847134  |
| Precision   | 0.964191  |
| Recall      | 0.755423  |
| Accuracy_a  | 0.841473  |
| f1_score_a  | 0.87455   |
| Precision_a | 0.964191  |
| Recall_a    | 0.800159  |
+-------------+-----------+
15:26:00: \begin{tabular}{lr}
\hline
             &     valid \\
\hline
 nonresponse & 0.0652883 \\
 Accuracy    & 0.813598  \\
 f1_score    & 0.847134  \\
 Precision   & 0.964191  \\
 Recall      & 0.755423  \\
 Accuracy_a  & 0.841473  \\
 f1_score_a  & 0.87455   \\
 Precision_a & 0.964191  \\
 Recall_a    & 0.800159  \\
\hline
\end{tabular}
15:26:00: @@@ Better score achieved at  k=200, harmonic pscore=True
15:26:00: current best score is 0.8471343777366936
15:26:00: Starting CV fit step
15:26:00: Hyperparameters: k=200, alpha=0.2, harmonic pscore=False
15:26:00: *_* Inside GetWP()
15:26:57: ######################################################################################
15:26:57: A data sample
15:26:57: +--------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+
|        | X                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |   Y |
|--------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----|
| 279035 | democrat  investigate   ukraine text    possible                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |   1 |
| 425038 | biden  harris name  person   year                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |   1 |
| 156036 | long reveal talk     female friend  finally  long believe  statement  cant        write  post   shock      need  vent       long   think woman           discriminate       raise  always respect boundary  handle woman    respect   anyone     part    mindset come   yesterday   good friend  mine burst       member   fraternity      female       never  problem        fraternity   almost every  member  least   appearance    decent   hold   moral towards woman like        talk     feel   fraternity    still enjoy  time    certainly   case      right   discus   deep subject like difficulty  parent  several childhood   answer  give  shock   boil    fact          fraternity  someway mistreat         hide  well   girl  keep stuff  stuff    avoid    example  stand          break      still   like serious emotional break stuff like      frat    talk     explain        difficult breakup  really  appreciate  behavior      emotional state  talk    something        would      good place     scenario    tell    afraid  drink   around      trust  member   take advantage     drink     admit  sleep   place  couple  time   night  heavy drink   transportation          sleep          clearly define side   never occur    even         minority   last group weekend  finally dare  hate       like   drink    quite    escort    room    already        another   already         room    next morning  wake  naked  remember   take  clothe      really      next    anything     reply     remember anything    offend    perform oral     night    explicitly         girl already   drink  form coherent sentence     able  stop anything  surprise  however  would also  quite obvious    respond    anyone   morality  leave   since   basically rape   book   shock      even want  remain  part   group     serious doubt    understandably    disgust  almost every member   fraternity   never     average          decide  leave  fraternity  leave second |   0 |
+--------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+
15:26:57: The shape of the data is (505676, 2)
15:26:57: 1    0.683711
0    0.316289
Name: Y, dtype: float64
15:26:57: Taking 20.0% test subset.
15:26:57: The resulting train shape is (404540, 2) and test shape is (101136, 2)
15:26:57: dividing data into classes
15:26:57: Joining the series of text into one string per category
15:26:58: Dividing those long strings into lists of words
15:26:58: Counting the occurrences of each word per class
15:26:58: Total umber of words (training+validation) is:
15:26:58: Class 1: 2527675, Class 0: 3903092
15:26:59: Number of distinct training words for each class is
15:26:59: 25052 and 48967
15:26:59: Visualizing the top 15 common words in each category [latex code below]
15:26:59: +--------------------------------------+
| Most common 15 words in each category  |
+----------------------+---------------+
|       class 1        |    class 0    |
+----------------------+---------------+
|        trump         |      like     |
|        biden         |      make     |
|        house         |      know     |
|     coronavirus      |     think     |
|         call         |      tell     |
|       democrat       |     would     |
|      president       |      want     |
|        white         |      take     |
|       election       |      time     |
|         vote         |     people    |
|      republican      |      feel     |
|        sander        |     start     |
|        state         |      year     |
|        donald        |      come     |
|       campaign       |      look     |
+----------------------+---------------+
15:26:59: \begin{tabular}{cc}
class 1 & class 0 \\
trump & like \\
biden & make \\
house & know \\
coronavirus & think \\
call & tell \\
democrat & would \\
president & want \\
white & take \\
election & time \\
vote & people \\
republican & feel \\
sander & start \\
state & year \\
donald & come \\
campaign & look \\
\end{tabular}
15:26:59: Starting CV fit step
15:26:59: Hyperparameters: k=200, alpha=0.5, harmonic pscore=True
15:26:59: *_* Inside GetWP()
15:27:02: WP created. Number of WP words are 332
15:27:02: P(y|wp) is calculated and saved to disk as REDDIT_CV_pywp_200.feather
15:27:02: Using fontManager instance from C:\Users\Khaled\.matplotlib\fontlist-v330.json
15:27:03: Loaded backend qtagg version unknown.
15:27:03: Loaded backend QtAgg version unknown.
15:27:03: Word Cloud
15:27:03: Top of class 1
15:27:03: Word Cloud
15:27:03: Top of class 0
15:31:13: +-------------+-----------+
|             |     valid |
|-------------+-----------|
| nonresponse | 0.0652883 |
| Accuracy    | 0.813598  |
| f1_score    | 0.847134  |
| Precision   | 0.964191  |
| Recall      | 0.755423  |
| Accuracy_a  | 0.841473  |
| f1_score_a  | 0.87455   |
| Precision_a | 0.964191  |
| Recall_a    | 0.800159  |
+-------------+-----------+
15:31:13: \begin{tabular}{lr}
\hline
             &     valid \\
\hline
 nonresponse & 0.0652883 \\
 Accuracy    & 0.813598  \\
 f1_score    & 0.847134  \\
 Precision   & 0.964191  \\
 Recall      & 0.755423  \\
 Accuracy_a  & 0.841473  \\
 f1_score_a  & 0.87455   \\
 Precision_a & 0.964191  \\
 Recall_a    & 0.800159  \\
\hline
\end{tabular}
15:31:13: @@@ Better score achieved at  k=200, harmonic pscore=True
15:31:13: current best score is 0.8471343777366936
15:31:13: Starting CV fit step
15:31:13: Hyperparameters: k=200, alpha=0.2, harmonic pscore=False
15:31:13: *_* Inside GetWP()
15:31:16: WP created. Number of WP words are 204
15:31:16: P(y|wp) is calculated and saved to disk as REDDIT_CV_pywp_200.feather
15:31:16: Word Cloud
15:31:16: Top of class 1
15:31:16: Word Cloud
15:31:16: Top of class 0
15:35:28: +-------------+----------+
|             |    valid |
|-------------+----------|
| nonresponse | 0.110811 |
| Accuracy    | 0.748467 |
| f1_score    | 0.780401 |
| Precision   | 0.968027 |
| Recall      | 0.653699 |
| Accuracy_a  | 0.800921 |
| f1_score_a  | 0.834701 |
| Precision_a | 0.968027 |
| Recall_a    | 0.733656 |
+-------------+----------+
15:35:28: \begin{tabular}{lr}
\hline
             &    valid \\
\hline
 nonresponse & 0.110811 \\
 Accuracy    & 0.748467 \\
 f1_score    & 0.780401 \\
 Precision   & 0.968027 \\
 Recall      & 0.653699 \\
 Accuracy_a  & 0.800921 \\
 f1_score_a  & 0.834701 \\
 Precision_a & 0.968027 \\
 Recall_a    & 0.733656 \\
\hline
\end{tabular}
15:35:28: Starting CV fit step
15:35:28: Hyperparameters: k=200, alpha=0.4, harmonic pscore=False
15:35:28: *_* Inside GetWP()
15:35:31: WP created. Number of WP words are 207
15:35:31: P(y|wp) is calculated and saved to disk as REDDIT_CV_pywp_200.feather
15:35:31: Word Cloud
15:35:31: Top of class 1
15:35:31: Word Cloud
15:35:31: Top of class 0
15:39:46: +-------------+----------+
|             |    valid |
|-------------+----------|
| nonresponse | 0.109269 |
| Accuracy    | 0.750465 |
| f1_score    | 0.782479 |
| Precision   | 0.968404 |
| Recall      | 0.656447 |
| Accuracy_a  | 0.802154 |
| f1_score_a  | 0.835895 |
| Precision_a | 0.968404 |
| Recall_a    | 0.735284 |
+-------------+----------+
15:39:46: \begin{tabular}{lr}
\hline
             &    valid \\
\hline
 nonresponse & 0.109269 \\
 Accuracy    & 0.750465 \\
 f1_score    & 0.782479 \\
 Precision   & 0.968404 \\
 Recall      & 0.656447 \\
 Accuracy_a  & 0.802154 \\
 f1_score_a  & 0.835895 \\
 Precision_a & 0.968404 \\
 Recall_a    & 0.735284 \\
\hline
\end{tabular}
15:39:46: Starting CV fit step
15:39:46: Hyperparameters: k=200, alpha=0.5, harmonic pscore=False
15:39:46: *_* Inside GetWP()
15:39:48: WP created. Number of WP words are 211
15:39:48: P(y|wp) is calculated and saved to disk as REDDIT_CV_pywp_200.feather
15:39:48: Word Cloud
15:39:48: Top of class 1
15:39:49: Word Cloud
15:39:49: Top of class 0
15:44:13: +-------------+----------+
|             |    valid |
|-------------+----------|
| nonresponse | 0.10737  |
| Accuracy    | 0.752136 |
| f1_score    | 0.784317 |
| Precision   | 0.968159 |
| Recall      | 0.659151 |
| Accuracy_a  | 0.802718 |
| f1_score_a  | 0.836558 |
| Precision_a | 0.968159 |
| Recall_a    | 0.736452 |
+-------------+----------+
15:44:13: \begin{tabular}{lr}
\hline
             &    valid \\
\hline
 nonresponse & 0.10737  \\
 Accuracy    & 0.752136 \\
 f1_score    & 0.784317 \\
 Precision   & 0.968159 \\
 Recall      & 0.659151 \\
 Accuracy_a  & 0.802718 \\
 f1_score_a  & 0.836558 \\
 Precision_a & 0.968159 \\
 Recall_a    & 0.736452 \\
\hline
\end{tabular}
15:44:13: Starting CV fit step
15:44:13: Hyperparameters: k=200, alpha=0.6, harmonic pscore=False
15:44:13: *_* Inside GetWP()
15:44:16: WP created. Number of WP words are 216
15:44:16: P(y|wp) is calculated and saved to disk as REDDIT_CV_pywp_200.feather
15:44:16: Word Cloud
15:44:16: Top of class 1
15:44:16: Word Cloud
15:44:16: Top of class 0
15:48:35: +-------------+----------+
|             |    valid |
|-------------+----------|
| nonresponse | 0.104444 |
| Accuracy    | 0.755656 |
| f1_score    | 0.788167 |
| Precision   | 0.967649 |
| Recall      | 0.664849 |
| Accuracy_a  | 0.804743 |
| f1_score_a  | 0.838686 |
| Precision_a | 0.967649 |
| Recall_a    | 0.740056 |
+-------------+----------+
15:48:35: \begin{tabular}{lr}
\hline
             &    valid \\
\hline
 nonresponse & 0.104444 \\
 Accuracy    & 0.755656 \\
 f1_score    & 0.788167 \\
 Precision   & 0.967649 \\
 Recall      & 0.664849 \\
 Accuracy_a  & 0.804743 \\
 f1_score_a  & 0.838686 \\
 Precision_a & 0.967649 \\
 Recall_a    & 0.740056 \\
\hline
\end{tabular}
15:48:35: Starting CV fit step
15:48:35: Hyperparameters: k=200, alpha=0.8, harmonic pscore=False
15:48:35: *_* Inside GetWP()
15:48:37: WP created. Number of WP words are 240
15:48:37: P(y|wp) is calculated and saved to disk as REDDIT_CV_pywp_200.feather
15:48:38: Word Cloud
15:48:38: Top of class 1
15:48:38: Word Cloud
15:48:38: Top of class 0
15:52:54: +-------------+-----------+
|             |     valid |
|-------------+-----------|
| nonresponse | 0.0931024 |
| Accuracy    | 0.774017  |
| f1_score    | 0.807551  |
| Precision   | 0.96656   |
| Recall      | 0.693469  |
| Accuracy_a  | 0.817455  |
| f1_score_a  | 0.851368  |
| Precision_a | 0.96656   |
| Recall_a    | 0.760708  |
+-------------+-----------+
15:52:54: \begin{tabular}{lr}
\hline
             &     valid \\
\hline
 nonresponse & 0.0931024 \\
 Accuracy    & 0.774017  \\
 f1_score    & 0.807551  \\
 Precision   & 0.96656   \\
 Recall      & 0.693469  \\
 Accuracy_a  & 0.817455  \\
 f1_score_a  & 0.851368  \\
 Precision_a & 0.96656   \\
 Recall_a    & 0.760708  \\
\hline
\end{tabular}
15:52:54: @@@ reached end of training.
15:52:54: best score is 0.8471343777366936, and best parameters are:
15:52:54: k=200, alpha=-1
15:52:54: Starting CV fit step
15:52:54: Hyperparameters: k=400, alpha=0.8, harmonic pscore=True
15:52:54: *_* Inside GetWP()
15:52:57: WP created. Number of WP words are 633
15:52:57: P(y|wp) is calculated and saved to disk as REDDIT_CV_pywp_400.feather
15:52:57: Word Cloud
15:52:57: Top of class 1
15:52:58: Word Cloud
15:52:58: Top of class 0
15:57:25: +-------------+-----------+
|             |     valid |
|-------------+-----------|
| nonresponse | 0.0306122 |
| Accuracy    | 0.843785  |
| f1_score    | 0.874904  |
| Precision   | 0.96677   |
| Recall      | 0.798982  |
| Accuracy_a  | 0.854886  |
| f1_score_a  | 0.885931  |
| Precision_a | 0.96677   |
| Recall_a    | 0.817568  |
+-------------+-----------+
15:57:25: \begin{tabular}{lr}
\hline
             &     valid \\
\hline
 nonresponse & 0.0306122 \\
 Accuracy    & 0.843785  \\
 f1_score    & 0.874904  \\
 Precision   & 0.96677   \\
 Recall      & 0.798982  \\
 Accuracy_a  & 0.854886  \\
 f1_score_a  & 0.885931  \\
 Precision_a & 0.96677   \\
 Recall_a    & 0.817568  \\
\hline
\end{tabular}
15:57:25: @@@ Better score achieved at  k=400, harmonic pscore=True
15:57:25: current best score is 0.8749039946157805
15:57:25: Starting CV fit step
15:57:25: Hyperparameters: k=400, alpha=0.2, harmonic pscore=False
15:57:25: *_* Inside GetWP()
15:57:27: WP created. Number of WP words are 408
15:57:27: P(y|wp) is calculated and saved to disk as REDDIT_CV_pywp_400.feather
15:57:27: Word Cloud
15:57:27: Top of class 1
15:57:28: Word Cloud
15:57:28: Top of class 0
16:00:16: ######################################################################################
16:00:16: A data sample
16:00:16: +--------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+
|        | X                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |   Y |
|--------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----|
|  50849 | think  trump administration      happen                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |   1 |
| 267748 | democrat raphael     america   military  also serve    daily wire                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |   1 |
| 229640 | tifu  make  meme page   high school  event happen     still partially   okay     stage   follow event manifest  self     background   city   school board  public school board  another     public school board   high school  include mine   catholic school board      teacher   high school    respect among  student body      amaze senior football   call  teacher     legendary meme status    many spoof edit  thing   like make   honour    ready   would take thing  bite   comply many quick meme edit    also current event occur     contact  friend  agree  help    maintain  account          decide   name   account    first    bigtamemes  pretty much  plan   gain   follower   first     previously state    football coach    football instagram page     make  note  occasionally     post   late admit      late  account completely blow  amass    follower      second week  grow   remember   around  moment  time     science class post  late bigtameme   classmate beside    look     respond         shock look    even    satisfaction reflect upon        popular      around  instagram follower   account    bigtamemes  take     large margin  kind  upset   request   friend  include  instagram name      know   idiot       seem   another memory      friend  help    account invite invite   come   workout session     remember   first walk    congratulate     recent meme        something along  line   like   post keep    city like many others  mild conflict   high  nothing serious  debate     best football  hockey team  thing       post comment upon  fact state  school clear superiority      seem like  minor detail   turn    huge consequence     please note   vast vast majority   post   mention another     example   post  create    huge impact      week           point  growth begin  stagnate however  still gain  occasional follower     meme    hundred    friend     could    part   meme   show     meme  make  agree    give access   account along side    name      next  week   half thing  look well         yesterday  school transportation  shut      storm  none       first friend receive  call   high school principal tell    president   catholic school board contact  request   remove  account base    content  make  paint    negative        idea   meme page enter  another school board field  vision   even   comply    fear    respect   school        instead        delete    meme  decide    follower  explanation   happen   give    tell  everything  happen   catholic school board  apparently  underestimate   intently   watch     hour late  friend    phone call tell   remove  previous post description   something  would   give  catholic board            large portion   follower    original post      comment  suggestive thing   catholic school   comment section   post      even comment   official catholic school instagram  comment     back   thing     obviously anger  even    next   three    separately call      first friend  first    sure exactly         leave  bigtameme page  completely    next   principal tell         discussion   head   catholic school  discus  punishment    meantime     also call      much  comment harsh thing   post comment   call    proceed  describe  post  detail     keep  straight    tell    catholic board tell      post  particular     provide  link     make  mockery   catholic  although  admit  think    meme  funny       highly inappropriate    mainly   avoid conflict   catholic school   news travel quickly   instagram post   previous    remember  first thing  hear  walk back  class  someone   hallway    hear   happen    period late     french     friend    call    office  time  discus  punishment  together    consist      school      unaware   basically  room  student  give    work     must complete        enter  room  first class begin  cannot leave   last class   along side      write  apology letter   catholic school board apologize   meme  offend    seriously think    secret message   though like maybe     first letter  every sentence spell      something like   final punishment   police officer    talk     danger  social medium  stuff       story conclude    tomorrow    first     wish  luck      weird part   whole ordeal       school     even    teacher     trouble  rather  school board        affiliate    make  meme page   school  another school board    become offend   make meme    shut |   0 |
+--------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+
16:00:16: The shape of the data is (505676, 2)
16:00:16: 1    0.683711
0    0.316289
Name: Y, dtype: float64
16:00:16: Taking 20.0% test subset.
16:00:16: The resulting train shape is (404540, 2) and test shape is (101136, 2)
16:00:16: dividing data into classes
16:00:16: Joining the series of text into one string per category
16:00:17: Dividing those long strings into lists of words
16:00:17: Counting the occurrences of each word per class
16:00:17: Total umber of words (training+validation) is:
16:00:17: Class 1: 2527675, Class 0: 3903092
16:00:18: Number of distinct training words for each class is
16:00:18: 25052 and 48967
16:00:18: Visualizing the top 15 common words in each category [latex code below]
16:00:19: +--------------------------------------+
| Most common 15 words in each category  |
+----------------------+---------------+
|       class 1        |    class 0    |
+----------------------+---------------+
|        trump         |      like     |
|        biden         |      make     |
|        house         |      know     |
|     coronavirus      |     think     |
|         call         |      tell     |
|       democrat       |     would     |
|      president       |      want     |
|        white         |      take     |
|       election       |      time     |
|         vote         |     people    |
|      republican      |      feel     |
|        sander        |     start     |
|        state         |      year     |
|        donald        |      come     |
|       campaign       |      look     |
+----------------------+---------------+
16:00:19: \begin{tabular}{cc}
class 1 & class 0 \\
trump & like \\
biden & make \\
house & know \\
coronavirus & think \\
call & tell \\
democrat & would \\
president & want \\
white & take \\
election & time \\
vote & people \\
republican & feel \\
sander & start \\
state & year \\
donald & come \\
campaign & look \\
\end{tabular}
16:00:19: Starting CV fit step
16:00:19: Hyperparameters: k=200, alpha=0.5, harmonic pscore=True
16:00:19: *_* Inside GetWP()
16:00:21: WP created. Number of WP words are 332
16:00:21: P(y|wp) is calculated and saved to disk as REDDIT_CV_pywp_200.feather
16:00:21: Using fontManager instance from C:\Users\Khaled\.matplotlib\fontlist-v330.json
16:00:22: Loaded backend qtagg version unknown.
16:00:22: Loaded backend QtAgg version unknown.
16:00:22: Word Cloud
16:00:22: Top of class 1
16:00:22: Word Cloud
16:00:22: Top of class 0
16:05:39: +-------------+-----------+
|             |     valid |
|-------------+-----------|
| nonresponse | 0.0652883 |
| Accuracy    | 0.813598  |
| f1_score    | 0.847134  |
| Precision   | 0.964191  |
| Recall      | 0.755423  |
| Accuracy_a  | 0.841473  |
| f1_score_a  | 0.87455   |
| Precision_a | 0.964191  |
| Recall_a    | 0.800159  |
+-------------+-----------+
16:05:39: \begin{tabular}{lr}
\hline
             &     valid \\
\hline
 nonresponse & 0.0652883 \\
 Accuracy    & 0.813598  \\
 f1_score    & 0.847134  \\
 Precision   & 0.964191  \\
 Recall      & 0.755423  \\
 Accuracy_a  & 0.841473  \\
 f1_score_a  & 0.87455   \\
 Precision_a & 0.964191  \\
 Recall_a    & 0.800159  \\
\hline
\end{tabular}
16:05:39: @@@ Better score achieved at  k=200, harmonic pscore=True
16:05:39: current best score is 0.8471343777366936
16:05:39: Starting CV fit step
16:05:39: Hyperparameters: k=200, alpha=0.5, harmonic pscore=False
16:05:39: *_* Inside GetWP()
16:05:42: WP created. Number of WP words are 211
16:05:42: P(y|wp) is calculated and saved to disk as REDDIT_CV_pywp_200.feather
16:05:42: Word Cloud
16:05:42: Top of class 1
16:05:43: Word Cloud
16:05:43: Top of class 0
16:10:56: +-------------+----------+
|             |    valid |
|-------------+----------|
| nonresponse | 0.10737  |
| Accuracy    | 0.752136 |
| f1_score    | 0.784317 |
| Precision   | 0.968159 |
| Recall      | 0.659151 |
| Accuracy_a  | 0.802718 |
| f1_score_a  | 0.836558 |
| Precision_a | 0.968159 |
| Recall_a    | 0.736452 |
+-------------+----------+
16:10:56: \begin{tabular}{lr}
\hline
             &    valid \\
\hline
 nonresponse & 0.10737  \\
 Accuracy    & 0.752136 \\
 f1_score    & 0.784317 \\
 Precision   & 0.968159 \\
 Recall      & 0.659151 \\
 Accuracy_a  & 0.802718 \\
 f1_score_a  & 0.836558 \\
 Precision_a & 0.968159 \\
 Recall_a    & 0.736452 \\
\hline
\end{tabular}
16:10:56: @@@ reached end of training.
16:10:56: best score is 0.8471343777366936, and best parameters are:
16:10:56: k=200, alpha=-1
16:10:56: Starting CV fit step
16:10:56: Hyperparameters: k=400, alpha=0.5, harmonic pscore=True
16:10:56: *_* Inside GetWP()
16:10:59: WP created. Number of WP words are 633
16:10:59: P(y|wp) is calculated and saved to disk as REDDIT_CV_pywp_400.feather
16:10:59: Word Cloud
16:10:59: Top of class 1
16:11:00: Word Cloud
16:11:00: Top of class 0
16:16:18: +-------------+-----------+
|             |     valid |
|-------------+-----------|
| nonresponse | 0.0306122 |
| Accuracy    | 0.843785  |
| f1_score    | 0.874904  |
| Precision   | 0.96677   |
| Recall      | 0.798982  |
| Accuracy_a  | 0.854886  |
| f1_score_a  | 0.885931  |
| Precision_a | 0.96677   |
| Recall_a    | 0.817568  |
+-------------+-----------+
16:16:18: \begin{tabular}{lr}
\hline
             &     valid \\
\hline
 nonresponse & 0.0306122 \\
 Accuracy    & 0.843785  \\
 f1_score    & 0.874904  \\
 Precision   & 0.96677   \\
 Recall      & 0.798982  \\
 Accuracy_a  & 0.854886  \\
 f1_score_a  & 0.885931  \\
 Precision_a & 0.96677   \\
 Recall_a    & 0.817568  \\
\hline
\end{tabular}
16:16:18: @@@ Better score achieved at  k=400, harmonic pscore=True
16:16:18: current best score is 0.8749039946157805
16:16:18: Starting CV fit step
16:16:18: Hyperparameters: k=400, alpha=0.5, harmonic pscore=False
16:16:18: *_* Inside GetWP()
16:16:20: WP created. Number of WP words are 422
16:16:20: P(y|wp) is calculated and saved to disk as REDDIT_CV_pywp_400.feather
16:16:21: Word Cloud
16:16:21: Top of class 1
16:16:21: Word Cloud
16:16:21: Top of class 0
16:20:39: +-------------+-----------+
|             |     valid |
|-------------+-----------|
| nonresponse | 0.0486474 |
| Accuracy    | 0.811798  |
| f1_score    | 0.845086  |
| Precision   | 0.966437  |
| Recall      | 0.75081   |
| Accuracy_a  | 0.831795  |
| f1_score_a  | 0.865154  |
| Precision_a | 0.966437  |
| Recall_a    | 0.783085  |
+-------------+-----------+
16:20:39: \begin{tabular}{lr}
\hline
             &     valid \\
\hline
 nonresponse & 0.0486474 \\
 Accuracy    & 0.811798  \\
 f1_score    & 0.845086  \\
 Precision   & 0.966437  \\
 Recall      & 0.75081   \\
 Accuracy_a  & 0.831795  \\
 f1_score_a  & 0.865154  \\
 Precision_a & 0.966437  \\
 Recall_a    & 0.783085  \\
\hline
\end{tabular}
16:20:39: @@@ reached end of training.
16:20:39: best score is 0.8749039946157805, and best parameters are:
16:20:39: k=400, alpha=-1
16:20:39: Starting CV fit step
16:20:39: Hyperparameters: k=600, alpha=0.5, harmonic pscore=True
16:20:39: *_* Inside GetWP()
16:20:42: WP created. Number of WP words are 931
16:20:42: P(y|wp) is calculated and saved to disk as REDDIT_CV_pywp_600.feather
16:20:42: Word Cloud
16:20:42: Top of class 1
16:20:43: Word Cloud
16:20:43: Top of class 0
16:24:48: +-------------+-----------+
|             |     valid |
|-------------+-----------|
| nonresponse | 0.0187371 |
| Accuracy    | 0.857598  |
| f1_score    | 0.886995  |
| Precision   | 0.969536  |
| Recall      | 0.817406  |
| Accuracy_a  | 0.863716  |
| f1_score_a  | 0.893141  |
| Precision_a | 0.969536  |
| Recall_a    | 0.827906  |
+-------------+-----------+
16:24:48: \begin{tabular}{lr}
\hline
             &     valid \\
\hline
 nonresponse & 0.0187371 \\
 Accuracy    & 0.857598  \\
 f1_score    & 0.886995  \\
 Precision   & 0.969536  \\
 Recall      & 0.817406  \\
 Accuracy_a  & 0.863716  \\
 f1_score_a  & 0.893141  \\
 Precision_a & 0.969536  \\
 Recall_a    & 0.827906  \\
\hline
\end{tabular}
16:24:48: @@@ Better score achieved at  k=600, harmonic pscore=True
16:24:48: current best score is 0.886995276430802
16:24:48: Starting CV fit step
16:24:48: Hyperparameters: k=600, alpha=0.5, harmonic pscore=False
16:24:48: *_* Inside GetWP()
16:24:51: WP created. Number of WP words are 633
16:24:51: P(y|wp) is calculated and saved to disk as REDDIT_CV_pywp_600.feather
16:24:51: Word Cloud
16:24:51: Top of class 1
16:24:52: Word Cloud
16:24:52: Top of class 0
16:29:14: +-------------+----------+
|             |    valid |
|-------------+----------|
| nonresponse | 0.030286 |
| Accuracy    | 0.834856 |
| f1_score    | 0.866668 |
| Precision   | 0.967283 |
| Recall      | 0.785012 |
| Accuracy_a  | 0.846135 |
| f1_score_a  | 0.877966 |
| Precision_a | 0.967283 |
| Recall_a    | 0.803749 |
+-------------+----------+
16:29:14: \begin{tabular}{lr}
\hline
             &    valid \\
\hline
 nonresponse & 0.030286 \\
 Accuracy    & 0.834856 \\
 f1_score    & 0.866668 \\
 Precision   & 0.967283 \\
 Recall      & 0.785012 \\
 Accuracy_a  & 0.846135 \\
 f1_score_a  & 0.877966 \\
 Precision_a & 0.967283 \\
 Recall_a    & 0.803749 \\
\hline
\end{tabular}
16:29:14: @@@ reached end of training.
16:29:14: best score is 0.886995276430802, and best parameters are:
16:29:14: k=600, alpha=-1
16:29:14: Starting CV fit step
16:29:14: Hyperparameters: k=800, alpha=0.5, harmonic pscore=True
16:29:14: *_* Inside GetWP()
16:29:17: WP created. Number of WP words are 1213
16:29:17: P(y|wp) is calculated and saved to disk as REDDIT_CV_pywp_800.feather
16:29:17: Word Cloud
16:29:17: Top of class 1
16:29:18: Word Cloud
16:29:18: Top of class 0
16:33:42: +-------------+----------+
|             |    valid |
|-------------+----------|
| nonresponse | 0.013556 |
| Accuracy    | 0.865201 |
| f1_score    | 0.893578 |
| Precision   | 0.970825 |
| Recall      | 0.827717 |
| Accuracy_a  | 0.869423 |
| f1_score_a  | 0.897825 |
| Precision_a | 0.970825 |
| Recall_a    | 0.835035 |
+-------------+----------+
16:33:42: \begin{tabular}{lr}
\hline
             &    valid \\
\hline
 nonresponse & 0.013556 \\
 Accuracy    & 0.865201 \\
 f1_score    & 0.893578 \\
 Precision   & 0.970825 \\
 Recall      & 0.827717 \\
 Accuracy_a  & 0.869423 \\
 f1_score_a  & 0.897825 \\
 Precision_a & 0.970825 \\
 Recall_a    & 0.835035 \\
\hline
\end{tabular}
16:33:42: @@@ Better score achieved at  k=800, harmonic pscore=True
16:33:42: current best score is 0.8935778240946738
16:33:42: Starting CV fit step
16:33:42: Hyperparameters: k=800, alpha=0.5, harmonic pscore=False
16:33:42: *_* Inside GetWP()
16:33:47: WP created. Number of WP words are 836
16:33:47: P(y|wp) is calculated and saved to disk as REDDIT_CV_pywp_800.feather
16:33:47: Word Cloud
16:33:47: Top of class 1
16:33:49: Word Cloud
16:33:49: Top of class 0
16:38:03: +-------------+-----------+
|             |     valid |
|-------------+-----------|
| nonresponse | 0.0218617 |
| Accuracy    | 0.842746  |
| f1_score    | 0.873676  |
| Precision   | 0.96911   |
| Recall      | 0.795352  |
| Accuracy_a  | 0.85026   |
| f1_score_a  | 0.881313  |
| Precision_a | 0.96911   |
| Recall_a    | 0.808102  |
+-------------+-----------+
16:38:03: \begin{tabular}{lr}
\hline
             &     valid \\
\hline
 nonresponse & 0.0218617 \\
 Accuracy    & 0.842746  \\
 f1_score    & 0.873676  \\
 Precision   & 0.96911   \\
 Recall      & 0.795352  \\
 Accuracy_a  & 0.85026   \\
 f1_score_a  & 0.881313  \\
 Precision_a & 0.96911   \\
 Recall_a    & 0.808102  \\
\hline
\end{tabular}
16:38:03: @@@ reached end of training.
16:38:03: best score is 0.8935778240946738, and best parameters are:
16:38:03: k=800, alpha=-1
16:38:03: Starting CV fit step
16:38:03: Hyperparameters: k=1000, alpha=0.5, harmonic pscore=True
16:38:03: *_* Inside GetWP()
16:38:05: WP created. Number of WP words are 1490
16:38:05: P(y|wp) is calculated and saved to disk as REDDIT_CV_pywp_1000.feather
16:38:06: Word Cloud
16:38:06: Top of class 1
16:38:06: Word Cloud
16:38:06: Top of class 0
16:42:12: +-------------+-----------+
|             |     valid |
|-------------+-----------|
| nonresponse | 0.0104216 |
| Accuracy    | 0.870995  |
| f1_score    | 0.898476  |
| Precision   | 0.972525  |
| Recall      | 0.834905  |
| Accuracy_a  | 0.874033  |
| f1_score_a  | 0.901562  |
| Precision_a | 0.972525  |
| Recall_a    | 0.840251  |
+-------------+-----------+
16:42:12: \begin{tabular}{lr}
\hline
             &     valid \\
\hline
 nonresponse & 0.0104216 \\
 Accuracy    & 0.870995  \\
 f1_score    & 0.898476  \\
 Precision   & 0.972525  \\
 Recall      & 0.834905  \\
 Accuracy_a  & 0.874033  \\
 f1_score_a  & 0.901562  \\
 Precision_a & 0.972525  \\
 Recall_a    & 0.840251  \\
\hline
\end{tabular}
16:42:12: @@@ Better score achieved at  k=1000, harmonic pscore=True
16:42:12: current best score is 0.8984756168732637
16:42:12: Starting CV fit step
16:42:12: Hyperparameters: k=1000, alpha=0.5, harmonic pscore=False
16:42:12: *_* Inside GetWP()
16:42:14: WP created. Number of WP words are 1040
16:42:14: P(y|wp) is calculated and saved to disk as REDDIT_CV_pywp_1000.feather
16:42:14: Word Cloud
16:42:14: Top of class 1
16:42:15: Word Cloud
16:42:15: Top of class 0
16:46:30: +-------------+-----------+
|             |     valid |
|-------------+-----------|
| nonresponse | 0.0159389 |
| Accuracy    | 0.853919  |
| f1_score    | 0.883543  |
| Precision   | 0.971064  |
| Recall      | 0.810493  |
| Accuracy_a  | 0.859009  |
| f1_score_a  | 0.888741  |
| Precision_a | 0.971064  |
| Recall_a    | 0.819285  |
+-------------+-----------+
16:46:30: \begin{tabular}{lr}
\hline
             &     valid \\
\hline
 nonresponse & 0.0159389 \\
 Accuracy    & 0.853919  \\
 f1_score    & 0.883543  \\
 Precision   & 0.971064  \\
 Recall      & 0.810493  \\
 Accuracy_a  & 0.859009  \\
 f1_score_a  & 0.888741  \\
 Precision_a & 0.971064  \\
 Recall_a    & 0.819285  \\
\hline
\end{tabular}
16:46:30: @@@ reached end of training.
16:46:30: best score is 0.8984756168732637, and best parameters are:
16:46:30: k=1000, alpha=-1
16:46:30: Starting CV fit step
16:46:30: Hyperparameters: k=1200, alpha=0.5, harmonic pscore=True
16:46:30: *_* Inside GetWP()
16:46:33: WP created. Number of WP words are 1766
16:46:33: P(y|wp) is calculated and saved to disk as REDDIT_CV_pywp_1200.feather
16:46:33: Word Cloud
16:46:33: Top of class 1
16:46:33: Word Cloud
16:46:33: Top of class 0
16:50:41: +-------------+------------+
|             |      valid |
|-------------+------------|
| nonresponse | 0.00839464 |
| Accuracy    | 0.873616   |
| f1_score    | 0.900662   |
| Precision   | 0.973473   |
| Recall      | 0.837985   |
| Accuracy_a  | 0.875966   |
| f1_score_a  | 0.903069   |
| Precision_a | 0.973473   |
| Recall_a    | 0.842163   |
+-------------+------------+
16:50:41: \begin{tabular}{lr}
\hline
             &      valid \\
\hline
 nonresponse & 0.00839464 \\
 Accuracy    & 0.873616   \\
 f1_score    & 0.900662   \\
 Precision   & 0.973473   \\
 Recall      & 0.837985   \\
 Accuracy_a  & 0.875966   \\
 f1_score_a  & 0.903069   \\
 Precision_a & 0.973473   \\
 Recall_a    & 0.842163   \\
\hline
\end{tabular}
16:50:41: @@@ Better score achieved at  k=1200, harmonic pscore=True
16:50:41: current best score is 0.9006621487192241
16:50:41: Starting CV fit step
16:50:41: Hyperparameters: k=1200, alpha=0.5, harmonic pscore=False
16:50:41: *_* Inside GetWP()
16:50:43: WP created. Number of WP words are 1249
16:50:43: P(y|wp) is calculated and saved to disk as REDDIT_CV_pywp_1200.feather
16:50:44: Word Cloud
16:50:44: Top of class 1
16:50:44: Word Cloud
16:50:44: Top of class 0
16:54:56: +-------------+-----------+
|             |     valid |
|-------------+-----------|
| nonresponse | 0.0128836 |
| Accuracy    | 0.859091  |
| f1_score    | 0.888014  |
| Precision   | 0.972362  |
| Recall      | 0.817131  |
| Accuracy_a  | 0.863111  |
| f1_score_a  | 0.892115  |
| Precision_a | 0.972362  |
| Recall_a    | 0.824103  |
+-------------+-----------+
16:54:56: \begin{tabular}{lr}
\hline
             &     valid \\
\hline
 nonresponse & 0.0128836 \\
 Accuracy    & 0.859091  \\
 f1_score    & 0.888014  \\
 Precision   & 0.972362  \\
 Recall      & 0.817131  \\
 Accuracy_a  & 0.863111  \\
 f1_score_a  & 0.892115  \\
 Precision_a & 0.972362  \\
 Recall_a    & 0.824103  \\
\hline
\end{tabular}
16:54:56: @@@ reached end of training.
16:54:56: best score is 0.9006621487192241, and best parameters are:
16:54:56: k=1200, alpha=-1
16:54:56: Starting CV fit step
16:54:56: Hyperparameters: k=1400, alpha=0.5, harmonic pscore=True
16:54:56: *_* Inside GetWP()
16:55:01: WP created. Number of WP words are 2041
16:55:01: P(y|wp) is calculated and saved to disk as REDDIT_CV_pywp_1400.feather
16:55:02: Word Cloud
16:55:02: Top of class 1
16:55:03: Word Cloud
16:55:03: Top of class 0
17:31:24: +-------------+------------+
|             |      valid |
|-------------+------------|
| nonresponse | 0.00700047 |
| Accuracy    | 0.87586    |
| f1_score    | 0.902521   |
| Precision   | 0.974383   |
| Recall      | 0.84053    |
| Accuracy_a  | 0.877703   |
| f1_score_a  | 0.904438   |
| Precision_a | 0.974383   |
| Recall_a    | 0.843862   |
+-------------+------------+
17:31:24: \begin{tabular}{lr}
\hline
             &      valid \\
\hline
 nonresponse & 0.00700047 \\
 Accuracy    & 0.87586    \\
 f1_score    & 0.902521   \\
 Precision   & 0.974383   \\
 Recall      & 0.84053    \\
 Accuracy_a  & 0.877703   \\
 f1_score_a  & 0.904438   \\
 Precision_a & 0.974383   \\
 Recall_a    & 0.843862   \\
\hline
\end{tabular}
17:31:24: @@@ Better score achieved at  k=1400, harmonic pscore=True
17:31:24: current best score is 0.9025210214523629
17:31:24: Starting CV fit step
17:31:24: Hyperparameters: k=1400, alpha=0.5, harmonic pscore=False
17:31:24: *_* Inside GetWP()
17:31:26: WP created. Number of WP words are 1447
17:31:26: P(y|wp) is calculated and saved to disk as REDDIT_CV_pywp_1400.feather
17:31:26: Word Cloud
17:31:26: Top of class 1
17:31:27: Word Cloud
17:31:27: Top of class 0
17:47:37: +-------------+-----------+
|             |     valid |
|-------------+-----------|
| nonresponse | 0.0109358 |
| Accuracy    | 0.863491  |
| f1_score    | 0.891823  |
| Precision   | 0.973203  |
| Recall      | 0.823003  |
| Accuracy_a  | 0.86668   |
| f1_score_a  | 0.895119  |
| Precision_a | 0.973203  |
| Recall_a    | 0.828635  |
+-------------+-----------+
17:47:37: \begin{tabular}{lr}
\hline
             &     valid \\
\hline
 nonresponse & 0.0109358 \\
 Accuracy    & 0.863491  \\
 f1_score    & 0.891823  \\
 Precision   & 0.973203  \\
 Recall      & 0.823003  \\
 Accuracy_a  & 0.86668   \\
 f1_score_a  & 0.895119  \\
 Precision_a & 0.973203  \\
 Recall_a    & 0.828635  \\
\hline
\end{tabular}
17:47:37: @@@ reached end of training.
17:47:37: best score is 0.9025210214523629, and best parameters are:
17:47:37: k=1400, alpha=-1
